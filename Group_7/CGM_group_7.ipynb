{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGM_group_7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-gr_V0icEsk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbbEqZaxliDr",
        "colab_type": "code",
        "outputId": "737a0486-dd31-49d1-f0bb-2b8725118791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "# import cv2 as cv\n",
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "# # from random import shuffle\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import re\n",
        "import json\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding,Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Bidirectional,LSTM,GlobalMaxPool1D,Dense\n",
        "from tensorflow.contrib import rnn\n",
        "from sklearn.utils import shuffle\n",
        "import pandas as pd\n",
        "import tensorflow_hub as hub\n",
        "from sklearn.model_selection import train_test_split\n",
        "import statistics as st\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFAHbwFHmXKB",
        "colab_type": "code",
        "outputId": "14877e93-5d8e-4b76-a3c0-7f8017e457a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XzDE2E1OyUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_feed_image=np.load(\"/content/drive/My Drive/img_emd.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZKORmX7ziqS",
        "colab_type": "code",
        "outputId": "82625ddf-acec-4b94-cd78-718db5aa3ac9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_feed_image.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(301, 73, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9dEOOvTxYgF",
        "colab_type": "code",
        "outputId": "7079a7d5-16a0-4fdd-bc5b-4d5ccfd797be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/Charades_v1_train.csv')\n",
        "df2 = pd.read_csv(\"/content/drive/My Drive/vid_ids.csv\")\n",
        "vids = set()\n",
        "for i in df2[\"0\"]:\n",
        "  vids.add(i)\n",
        "script_dict={}\n",
        "for rows in df.itertuples(): \n",
        "  if rows.id in vids:\n",
        "    script_dict[rows.id]=rows.script\n",
        "print(script_dict)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'46GP8': 'A person cooking on a stove while watching something out a window.', 'N11GT': 'One person opens up a folded blanket, then sneezes and leaves the stairs with a broom.', 'KRF68': 'A person runs into their laundry room. They grasp the doorknob and close the door. The person starts dressing then leaves holding their phone.', 'MJO7C': 'A person runs into their pantry holding a bottle of medicine. They grab the doorknob and close the door while watching a video on their phone.', 'S6MPZ': 'A person is eating at the desk and lying the phone down.', '7HVU8': 'A person is throwing items into a bag then starts fixing their clothes.', 'MCQO5': 'A person is undressing in the closet.  They put their clothes back into the wardrobe and drink a glass of water while looking at a picture.', 'VPIYF': 'A person is standing by a shelf and grasping his phone off of it.', 'JSUF4': 'A person is sweeping up with a broom and putting things back in their place. They take break on the sofa and start drinking a water.', '8WJIR': 'A person in their bedroom is holding a glass of coffee that they picked up from the table. They are smiling because they see something funny on the television and then they start closing the bedroom door.', 'INQNU': 'A laughing person is fixing a bed in their bedroom while drinking a glass of milk.', 'LI6LV': 'In the bathroom, the person put a towel on the doorknob and started undressing.  Half way through they took some medicine from the counter and took it with a drink of water.', 'MGCM8': 'The young person was eating a sandwich while browsing on their laptop after working and standing all day long.', 'I8QJN': 'A person awakens on the floor of the kitchen. The person gets up, putting their hand on the edge of the stove to help. The person walks to the sink, and pours a large glass of water.', 'XC9EY': 'A person walks along the hallway, smiling as the person straightens a picture on the wall.  The person puts a glass down on a table.', 'DOQ9Y': 'A person undressing by removing their jacket in the pantry. They are looking for some food, and when they find some groceries, they decide on leaving the pantry while closing the door.', 'RK9II': 'A person is tidying up with a broom. Laughing, the person walks to the small end table and leans the broom against it.', 'QGQGZ': 'A person opens the door into the kitchen then turns the light on in. They then proceed to put the groceries away.', '5S1WQ': 'A person is closing the desk and then playing with a broom in the dining room.', 'CUCBN': 'A person smiles at a bag of groceries in the living room. A person leaves the groceries in the room and walks outside.', 'SX0HE': \"In a hallway, a person drinks from a glass and then holds a a phone to the person's ear.\", '72JYK': 'A person turns out a light, and then sits on the bottom step of a flight of stairs, eating some snack food while they watch media on their laptop.', 'BDFDE': 'A person is walking toward a chair. They sit in the chair and take some medicine.', 'H6N4Z': 'A person is putting clothes away on a shelf in a walk-in closet. The person is watching a video on a phone as they do this.', 'OBTP8': 'A person opens a door and enters a bedroom. They begin dressing in clothes and grab a box and leave.', '4021N': 'A person is tidying the laundry room. They throw a pillow into the corner and put a camera into a box.', 'ZSHWE': \"A person is walking down stairs while grasping a book.  The person has a towel draped over the person's shoulder and stops at the bottom of the stairs to undress.\", 'SFDTP': 'A person is seen dressing themselves. The person takes clothes out of the box and stands there looking at them.', 'Q5EPP': 'A person opens a bottle of medicine and plays with food.', 'SK6FW': 'A person is undressing their warm clothes. They see a broom and start playing with it, pretending it is a microphone.', 'VHIG7': 'A person is eating food, then laughing at a laptop in a basement.', '0R6K4': 'A person takes a glass of water from the desk and drinks it.', 'PSPMA': 'A person is seen watching television as they put on their shoes. They start laughing, then take a bit out of their food.', 'MD41D': 'A person is standing at the window and watching outside. They take a photograph through the window using a camera.', 'SDXZ8': 'A person walks into their kitchen and starts tidying up. The person washes the dishes and then vacuums the floor.', 'S673O': 'A person lies on a sofa in the living room, laughing as they watch television. The person pours a drink into their glass, and takes a bite of their sandwich.', 'U79C9': 'A person sits on stairs and takes off their shoes, then grabs a blanket and snuggles it.', 'N915C': 'A person is undressing as the person stands in front of the wardrobe. Then, wrapped in a blanket, the person picks up a broom and begins tidying the room.', 'FXRMG': 'A person takes a book from their desk. Holding the book, the person looks around and leaves the room.', 'P68QV': 'A person is seen smiling and looking at their camera. They begin eating and then pick up a bag of groceries to put away.', '78XZ9': 'A person is standing on a box and smiling at a book.', '0VOQC': 'One person runs in with a phone, then eats something out of a bag, then closes the bag.', 'E6Q95': 'A person is undressing and wrapping herself in a blanket. A person is walking to sit in front of the television and eat a sandwich.', 'G99VH': 'A person is smiling at a camera and then pouring medicine into a spoon on the stairs.', 'DWHPO': 'A person is sitting and smiling at another person who has a bag of food.', 'H603E': 'A person is reading a book while working on their laptop. The person puts the book down and starts eating.', 'CBXVQ': 'A person stands in front of their pantry pulling food off of the shelf , they walk to the sink grasping a piece of fruit and began washing it.', 'PN4MI': 'One person stands drinking and laughing in the doorway as another person awakens with homework and a sandwich in front of them.', 'VJ2QS': 'One person pours something down the sink, then sits at the table and plays with their food.', 'FI1LR': 'A person is cooking on the stove and another person is putting up groceries.', 'AY08E': 'A person is in the bedroom holding some clothes.  Then the person starts smiling while looking at themselves in the mirror.', '7XNAI': \"A smiling person is walking into a recreation room has set a sandwich next to the person's laptop.\", 'IST7I': 'Person is snuggling with blanket watching television and eating food out of box.', 'OI3BC': 'A person puts a towel onto a chair in their study. The person notices an open drawer in the nearby desk; the person closes it.', 'F4BJJ': 'A smiling person runs through the doorway.  The person puts a bag down on the desk.  The person takes a book out of the bag and stands by the desk holding it.', '83654': 'A person puts a sandwich down onto a desk. The person sits down at the desk, and opens a box.', '0G0YF': 'A person walks to a refrigerator, closes the refrigerator door, and then cooks at a stove.', '0R5GS': 'A person in the recreation room is walking around holding a box that they picked up from the desk. Their walking turns into running as they look into a mirror and see their reflection.', 'PVB4S': 'A person is walking down the stairs holding a bag in their hand.  When they get to the bottom of the stairs, the person throws the bag next to the sofa.', 'N2OCX': 'A person laughs while holding a broom in the basement, then sneezes on a chair.', 'Q5GVZ': 'A person is standing in the hallway holding a towel and a cup of coffee.  The person puts the towel onto a pile of clothes and fixes a crooked picture on the wall.', 'R7107': 'A person is working on a sofa. Another person walks in with a bag of groceries, closing the door behind them.', 'UMOE4': 'A person holds a box of pictures from a table in the entryway. Another person suddenly comes running through.', 'QLWQ4': 'A person is tidying up the room. They are holding a laundry bin and pick up a towel and a blanket nearby, and put it in the laundry bin.', 'S9P0W': 'A person is seen holding a towel which they put into a box. They then start pouring themselves some water and turning off the light', 'U1DTW': 'A person is tidying up with a broom. The person starts laughing because of something they noticed outside the window.', 'R6CIX': 'A person standing looks like they are fixing a door hinge but gets tired and sits on a sofa.', '2PREF': 'A person is in the kitchen holding a frying pan.  They put the pan on the stove and go to the shelf for a can of food.  The person opens the can and sets it next to the stove.', '57J92': 'One person grasps a broom and smiles at another person who is eating a sandwich and watching the first person.', 'R2DA8': 'A person is seen sneezing while on their laptop. The person then begins throwing food on a plate from the fridge.', 'VCU4P': 'A person is smiling and watching a person as the person folds a blanket and puts it into a cabinet.', 'U3OJV': 'A person is drinking coffee and grasping a phone with their other hand.', 'T1CQE': 'Person walks into the bedroom, takes their laptop out of a bag, and lies down on the bed.', 'FPNT1': 'A person walks up the stairs grasping a laptop and some homework.  Halfway up the stairs they throw the homework down.', '3ZKDY': 'A person snuggling with a blanket asleep on the sofa, begins awakening and sitting up with a yawn.', '3MAY9': 'A person holding a camera takes a picture of a cabinet.  They set the camera down, pick up a glass and start drinking as they turn out the light and walk away.', '0TQZQ': 'A person stands in front of the medicine cabinet, reading a book. The person closes the book, and runs out of the bathroom.', 'G70A2': 'A person is sneezing and then starts tidying the book on the shelf.', 'R00LO': 'A person is walking toward a pantry while snuggling a blanket. The person grabs a sandwich.', 'CMD0M': 'A person is tidying up some junk on the shelf.  Then the person pours some liquid into a glass.', '2WGSN': 'A person drinks from a cup then puts it in the sink and begins washing it with a towel.', 'KV99H': 'Person opens desk to messy clutter of shoes and glasses. Person tidies up by throwing things into bag.', 'EDVAM': 'A person is holding a pillow. Then, sneezing, the person gets up and begins closing the window.', 'R1S1Z': 'A person is taking groceries from a bag and throwing them to a person as the person stands by the fridge, ready to put them away.', 'FDYQZ': 'A person standing at a sink starts to undress. Another person runs by holding a pillow in their arms.', 'V3DJ5': 'One person snuggling under a blanket sneezes, smiles, then takes a piece of food.', '9GMHF': 'A person is laughing as the person hangs their coat up in the cabinet. Then the person opens the door and reaches for a broom to sweep out the entryway.', 'G6MYM': 'A person is in the entryway watching the mirror.  Another person is working on bringing in groceries to the house.', '7HZHM': 'A person is undressing in front of the mirror. They sneeze and grab a tissue from the tissue box.', 'XOMJ4': 'A person is taking medicine out of the cabinet.  The person pours a tablespoon of the medicine and drinks it, then puts it back in the cabinet and sits in a chair.', 'L2ZZB': 'A person is undressing in the hallway by taking their  jacket off. They start lying down on a blanket while pulling out their phone.', '5ACD3': 'A person lying on the floor in the living room is drinking their favorite beverage and watching something out the window.  They get up, bringing their empty glass with them, and put it on a table.', 'UAT1F': 'A person is standing while holding a book in their home office. They then walk over to a desk, put the book down and open a laptop.', 'MZOPX': 'A person is playing on their new laptop and then washes a glass they used earlier.', 'VLE11': 'A person is at a dining room table playing with a television remote, they then put the remote down and open up their homework book.', 'S67WR': 'A person is fixing a vacuum then opens the door to leave.', '00SL4': 'A person is opening a closet door. The person, smiling, then places a blanket on the shelf.', 'SYMIR': 'A person is standing in the hall undressing after work, taking off their shoes and jacket. This person places the shoes on a nearby towel.', 'U3VOM': 'One person is lying on a blanket by the door when another person throws down some clothes and leaves.', 'Q01UB': 'A person is dressing by putting on a jacket. Then the person puts some shoes next to an open laptop.', 'S72J9': 'A person drinks a glass of water while closing the dryer door. The person looks out the window.', '6EU06': 'A person can close a book in the hallway, A person can wash a table in the hallway.', 'PVVQS': 'A person walks in the kitchen and turns on the light. The are laughing and begin throwing their shoes.', 'FU2HI': 'A bag of groceries sit on a chair. A sneezing person is working a broom to death trying to sweep out the dusty corner.', 'MI76A': 'A person is lying on the sofa in their recreation room under a blanket and reading a book closes the book.', 'WFVD3': 'A person standing in the doorway opening, throws a book inside near a laptop.', 'XHQT1': 'A person is tidying shoes on a shelf in a garage. The person then walks through a doorway and exits the garage.', 'XECIL': 'A person is eating a sandwich in the pantry, and takes a bag of chips from the cabinet. The person wipes their hands with a paper towel.', 'TX020': 'A person runs into the garage, eating a sandwich. The person puts on a pair of shoes and leaves.', 'VAXUU': 'A person is seen taking a camera from their closet. They grasp the doorknob and begin closing the closet door.', 'UKCTK': 'One person takes a broom and a camera from the room and leaves, smiling.', 'AZC1I': 'A person is seen fixing a chair in the laundry room. They smile and sit in the chair, pulling out their laptop.', 'Q24KP': 'One person puts a blanket on a table while a other person is laughing next to a cabinet.', 'OOWJ9': 'A person is eating some food while they read a book. The pour a glass of water and start taking a drink.', '5Z1CO': 'A person is playing by trying to juggle the medicine, book, and food they just picked up while tidying.', 'DB4WX': 'A person is playing with a pillow. A person is smiling as the person watches her, leaning on a table.', 'UBVV7': 'Person puts blanket in box. Person smiles. Person eats small food item. Person closes box and puts box in closet.', 'AGWQA': 'A person walks into a laundry room and throws a towel in the dryer closing the door. The person then fixes the placement of detergents on the shelf.', 'TJBGM': \"A person is standing with a broom in the entryway.  The person then walking over to grab a book that's nearby.\", '0NFT7': 'A person is tidying up the garage by putting up some towels. A second person enters the doorway to hand the person a drink. The first person drinks from the glass as they walk out of the garage through the same doorway.', 'AX4EW': 'A person is eating in a dining room and then sneezes. Another person takes a picture of the person sneezing with a camera.', 'LT2IJ': 'A person is putting and taking, boxes and pictures from a cabinet.', 'X0CKA': 'Person is standing looking at a picture on a shelf. Person begins drinking a glass of water.', 'JZ9L4': 'A person is seen fixing clothes and sitting on a chair. The person begins holding a towel to put away.', 'MLDGN': 'A person in the laundry room is dressing by putting on some clothes. They see a picture on the laundry machine and start watching the picture.', 'VPJLN': 'A person turns the doorknob and runs in through the entryway holding some clothes.', 'CW9VO': 'A person watching the television sneezes and grabs a tissue from the desk.', 'XCUOD': 'A person in a towel is dressing for work. Another person is eating food at the kitchen table.', 'YQOPM': 'A person throws some clothes into a box. The person stands there for a moment, then removes the clothes and begins to fold them.', 'VJ3B5': 'A person is in the bathroom and there is an empty box in the sink.  The person picks up the box and throws it to the floor while laughing.', '1D31Z': 'A person is fixing a sandwich in the pantry. The person laughs as they take a drink from a glass of water, then leaves through the doorway.', 'LWP5F': 'A person is seen grasping a sandwich eating it. The person begins opening a box and pulls out some clothes.', 'HDDU0': 'A person is grasping their mug of coffee as the person works on their homework. Then, laughing, the person stands and walks to the refrigerator.', 'NMG2Z': 'A person is in a basement undressing from their clothes, they then start snuggling with their shirt by a closed door.', 'TU3IG': 'A person is holding a box while taking some medicine.', 'C1LJS': 'A person opens the bedroom door, walks through, closes it, then lies down on the bed.', 'WFWTU': 'A person runs into the garage, eating a piece of food. The person runs out, closing the door behind them.', 'KU2T0': 'A person is snuggling with a pillow while another person is lying next to a book.', '9WX7N': 'A person is sitting on the stairs with a pillow in their lap.  The person stands up and looks in the mirror, smiles, then sneezes.', '8W0XJ': 'A person closes the garage window and smiles. The person takes a camera from the shelf and snaps a picture.', 'IUW9N': 'A person walks into the bathroom, closing the door behind them. The person looks in the mirror and adjusts their clothes.', '3H0PT': 'A person is sitting at a desk eating food. They get up and leave the room closing the door behind them.', '9JIHR': 'A person is lying on the floor on a hallway kicking a door. The person then gets up and walks towards a box in the hallway.', 'W6QUC': 'One person washes the window with a towel as another lies on the floor fixing a broken chair.', 'XBXKO': 'A person is watching a video on their while washing clothes. The person takes some clothes out of the dryer and puts them into a box.', 'WYHPH': 'A person laughing at a camera while awakening next to a cabinet.', 'GLH5S': 'One person stands, opens a jar of medicine and sneezes, then puts it in a desk and closes it.', 'UU5XI': 'A person is fixing the doorknob.  Then a person is taking groceries out of the room.', 'PK2F0': 'A person walks into the bedroom holding a stack of clothing, they put the clothing down walk back to the door and close it they put away the clothing in the wardrobe and then lay down on the bed.', 'PXKFK': 'A person is smiling at the light outside the door.  Then a person is taking groceries inside that were in a bag by the door.', '7AH3L': 'A person is walking around a table, then lying on the floor, then using a vacuum and finally taking off shoes in a dining room.', 'C41G7': 'A person is tidying the hallway with a broom. They stop, and start playing with a television.', 'OOOQT': 'The person tidying the refrigerator stands near the doorway holding the door open, grasping at food.', 'O0C2Z': 'A person is throwing food in a sink and then holding a broom in a kitchen.', 'OEBAH': 'A person is walking along the hall holding a pair of shoes for playing golf and a towel.', '17AZ5': 'A person is dressing while walking down the hallway. The person sneezes, then takes out of bottle of medicine. The person turns out the light and leaves the hallway.', 'YPZQ2': 'The person is standing in the hallway with bags of groceries, while another person takes some of the groceries and leaves through the door.', 'MMKKS': 'Person of struggling to tidying up the hallway, by throwing stuff off the glass table.', 'BWKJB': 'A person takes a blanket from a chair and laughs as they fold it. The person gets distracted by their phone, and begins playing with it.', '7OPHI': 'A person opens their laptop and begins watching a video. After a moment, the person closes their laptop and grasps the doorknob.', 'R0207': 'A person in the hallway lying on the floor. The person begins working on the laptop begins eating a sandwich at the doorway.', 'U75AZ': 'A person is undressing in the laundry room.  The person grasps the side of a chair to steady their balance and knocks a book onto the floor.', 'MIV2M': 'A person opens a door and walks into their living room holding a bag. They pour them self a drink and sit on the sofa .', 'HXSMP': 'A person walks into the office, closes the door, and smiles into the mirror.', 'OVICR': 'A person is fixing a phone.  Then a person is sneezing while they put their homework in a pile.', 'QGHR6': 'A person in the living room is undressing by taking their jacket off. They begin eating some food and then take a broom that is lying by the window and placing it on the ground.', 'Z3DBQ': 'Person opens door to apartment.  Person turns on the light.  Person carries bags of groceries up the stairs.  Person gets to the top of the stairs and throws down the bags of groceries.  The person lets out a big smile.', 'SL9ZD': 'The person holding the box was working on setting up a chair on the second floor.', 'AZZVK': 'A person is tidying the house by sweeping a broom across the stairs. They are standing on the stairs with a light hanging above them.', 'FO2RD': 'A person smiles as they work on homework at a table. The person eats from a bag of chips.', 'MS3E8': 'A person smiles as they walk into the pantry, carrying a holding a box. The person sets the box down on a table, and begins laughing as they put the groceries away.', '1X765': 'A person is sitting in their laundry room, eating a sandwich and playing with their phone. The dryer finishes spinning and they walk to it to gather up all their clothes.', 'RGHXS': 'A person is laughing on the phone while washing a glass', 'VG9II': 'A person is drinking coffee and scoots a chair to them. It has a pillow on it and the person puts their feet up to take a break.', 'EN80R': 'A person is cooking on a stove, then the person starts taking medicine to help with a sickness.', 'HIOY0': \"A person wakes up on the sofa and takes the pillow out from under their head and throws it on the floor.  The person turns on the television and laughs at what's on it.\", 'LZ07A': 'A person is dressing as the person sits on the chair. Then, standing, the person reaches for their bag and leaves the room.', 'XV8CH': 'A person is cooking at the stove, taking a spoon out of a drawer.  Another person walks in the door and puts their keys on the table.', 'JCKRL': 'A person is walking through a doorway and sneezing, then drinking coffee in a recreation room / man cave.', 'RANB1': 'A person is undressing in the mirror while a other person is lying in bed.', 'VIKQG': 'A person runs into the living room and takes a pair of shoes from under a desk.', 'IR7CA': 'A person is seen taking a broom to sweep the bathroom. They begin sneezing and start looking inside of a nearby cabinet.', 'K2L7F': 'A person brings a broom into the bathroom.  The person sneezes violently three times.  They then lean the broom against the doorknob of the bathroom door, and they lie down on the floor of the bathroom in order to catch their breath from the sneezing.', 'JNWX7': 'A person grabbing a drink out of the refrigerator. The person closes the door and pours the drink into a glass. The person leaves the glass on the counter.', 'WLOCV': 'A person is playing peek-a-boo with another person in front of a mirror. They then take selfies in front of the mirror with a camera.', '94KP4': 'A person is standing in the bedroom eating a piece of fruit , they start looking on the table , they turn on the light so they can see better they pick up a book . Smile and leave the room .', '1Y5H7': 'A person is leaving the vacuum in the laundry room.  The person then then starts lying towels down.', 'KW4Y1': 'A person is undressing, then putting on clothes, and finally cleaning a mirror in a hallway.', 'WYYUD': 'A person is undressing in bed. Smiling, a person is taking their clothes and putting them in the hamper.', 'GKH4A': 'A person is using a vacuum to clean the foor. Then the person is tidying the sofa, taking a bag from the couch and setting it on the floor.', 'FLCZA': 'A person is lying on a blanket after drinking a glass of wine.', '1BUFQ': 'A person is walking back and forth in front of a television. They start sneezing, so they stop and stare at the ceiling to stop the sneezes. It works, so they smile while they sit and draw a picture.', 'KW3BO': 'Person is eating box of candy and drinking coffee then starts laughing.', 'CO1S9': 'One person walks into the pantry, grasps a box and a bag, then runs out.', 'N588B': 'A person is in a hallway putting a camera in a box, then they close the box and carry it out the doorway.', 'ZS1P1': 'One person sits working on a laptop laughing. A book is next to the laptop.', '2H5YP': 'A person is tidying up the bathroom. The person puts something into the medicine cabinet, closes the cabinet door, then looks into the mirror for a moment.', 'I6AZD': 'A person is sitting on a sofa covered with a blanket. The person stands, removes their shoes, and lays down.', '99DTF': 'A person is walking up the stairs while grasping a box. They pull a phone from the box.', 'QDINO': 'A person is lying on a pillow and then sneezing on dishes on a table in the dining room.', '3CPVF': 'After tidying up, a person grasps for their wine glass as they sit down on the sofa holding their phone.', 'QIQXR': 'A person puts on shoes, then grasps the vacuum and begins cleaning the floors.', 'SXYLN': 'A person in a garage is holding groceries and a sandwich. They put the bag down and start eating the sandwich. They throw the sandwich wrapper in the garbage and leave.', 'I6B5D': 'A person is grasping at a towel while washing their teeth and reading homework.', 'MJX48': 'A person puts a pair of shoes into a bag, then throws the bag up the stairs.', 'YMGGV': 'A person is watching television and smiling. Then, taking a blanket from the doorway, the person wraps it around herself.', 'J39ZC': 'A person is standing by a table.  A person is eating something from a box and drinking something.', 'C5BMA': 'The person was running through the kitchen, eating a sandwich and talking.  When the person finished running, the sandwich was put into the sink.', '2INEX': 'A person enters the dining room and sets their cup of coffee down. They start grasping clothes out of a laundry basket and throwing them on the floor.', 'GV40M': 'In a bedroom, a person is awakening. They look at a light and sneeze. Then they look towards the door and begin to get out of bed.', 'D8QFD': 'Person is playing on the phone near a window and smiling while he plays.', '0YXN6': 'A person is smiling while reading a book.  Another person standing in the doorway sneezes and blows their nose.', 'J12SC': 'A person takes their shoes off then opens a box and take a camera out while on some stairs.', 'H2ZYY': 'A person is opening the cabinet and taking their shoes off.', 'WMBOO': 'A person opens the door to the pantry and begins stocking it with some groceries. The person picks up a roll of paper towels from the floor and places it on the shelf, then leaves.', '3C36H': 'Person is sitting on chair doing homework, Another person opening bag and starts sneezing.', 'ZYVTC': 'A person is sitting on a pile of clothes eating food.  The person puts the food down and opens a book to read.  The person grabs their phone, gets up and leaves.', 'J40UT': 'A person in a bathroom is holding a glass. The person drinks the last of the coffee in a glass, then washes a glass in the sink. And begins tidying up the bathroom.', '9HGNV': 'A person walking into an entryway is snuggling a pillow and blanket.', 'HQZ29': 'A person is smiling and pouring milk on a bowl of cereal, then using a towel to wipe up spilt milk and finally putting bowl in sink in kitchen.', 'LW5O6': 'A person is tidying up the dining room with a vacuum, then smiles as they find a pair of shoes under the table.', 'PKEZI': 'Person A is in a bedroom eating a plate of food and reading a book.  Done eating, person A gets up and walks over to the wardrobe and begins undressing.', 'ZHLLU': 'A person is sitting on the floor looking at a mirror then they begin to sneeze holding a pillow.', 'F50DT': 'A person is watching a laptop while another person is smiling at a camera.', 'H3E1E': 'A person sits in the garage, drinking a cup of coffee while reading a book.', 'CXSYS': 'A person sneezes into a bag while sitting in a chair. They get up and start cooking at the stove.', 'JL3VT': 'A person runs into a bedroom and grabs a sandwich off a table. They walk out of the room.', '7P0HA': 'One person throws a bottle of medicine in the sink, then washes up and runs out with a pillow.', '2XG25': 'A person awakens in their bedroom.They look in a mirror, grab a laptop and leave.', 'MD6P2': 'A person is standing in the rec room grasping a bottle of medicine.  The person opens the medicine and pours it into a tablespoon.  After taking the medicine, the person closes the medicine and puts it back in a box.', 'YYMLT': 'A person is laughing at doing the homework on the laptop while standing by the vacuum.', 'V1PRP': 'A person is seen snuggling while sitting on a chair. They begin vacuuming the stairs while standing up.', 'X1R6D': 'A person walks into the bathroom, laughing. The person closes the door behind them, and washes their hands in the sink.', '29LL7': 'One person runs through, grasps a pair of shoes and some clothes, then leaves laughing.', '0OUEP': 'Two persons are sitting on the bed snuggling.  One person is holding a camera and a glass of water.  The other person gets up, grabs the doorknob, and closes the door.', '705RV': 'A person is seen fixing a sandwich. They then start putting the sandwich on a table and begin taking some medicine.', 'FKZTG': 'A person takes a sandwich and a book from a table in the hallway. The person leaves.', 'HOI88': 'A person is snuggling with a book while another person is grasping a desk.', 'SBMQX': 'A person is drinking a glass of juice while standing in the hall near the entrance to their house. A stranger is watching this scene through the side window.', 'CYLQ0': 'A person opens the door to a cabinet in their pantry. They grab a can of food and close the cabinet.', 'AEZDA': 'A person is eating from a bag of groceries in a hallway then starts playing with a vacuum.', '2BUDH': 'One person was grasping for some food. And then they started drinking in the light.', '2ZFG4': 'A person in the hallway is washing a window near a chair. They are smiling.', 'W2TL1': 'A person is sitting at a desk and throwing food at a television.', 'G7LU9': 'Person is in room. Person smells cooking, Person opens doorknob. Person hears laughing. Person closes door, sad.', 'WEYV3': 'A person is seen eating a sandwich at their desk. They begin holding their phone to make a call.', 'BIK4X': 'A person is lying on the sofa eating food.  They pick up a cup of coffee.', 'E7ESG': 'A person is lying down on a sofa, fast asleep. They awaken and look at the time on their phone. They then rush over to the desk, open a book and prepare to continue their homework.', 'KZK6W': 'A person is cooking food on the stove. The person pours some oil into the pan, then drinks from a glass of water.', 'A4SR3': 'A person is eating while watching television. The person begins laughing and places their food on the table.', 'CD11G': 'A person is cooking food on a stove, then opening a refrigerator and eating in a kitchen.', '0MFAM': 'A person is standing in the doorway.  Then a person is grasping a broom.', 'OVH9Y': 'A person is lying in bed while watching television. After a few seconds the person gets back to working on cleaning the room. The person walks over to a vacuum turns it on, vacuuming the floor for a bit.', '3W5GB': 'Person A is in a closet putting away some towels.  Person A throws one that is unpleasant looking and camera and a picture leaving the closet.', 'EASCD': 'The person pours out the rest of their soda into a glass and takes a drink.  Then they pick up their dirty dishes off the coffee table and carry them to the sink.', 'O1LOW': 'A person walks through a door into a hall and sees a book and other items on the floor. They pick up the book and tidy the area.', '3BVG1': 'A person puts a broom inside a hallway closet and closes the door. Another person is sitting in the hallway.', 'P5SWU': 'One person is holding the pillow while the other is fixing the television.', '7B1CR': 'A person sneezing at their phone then drinking out of a glass.', '2JKR8': 'A person is using a broom. After they are finished they leave it in the sink and begin taking some food to bring into another room.', 'WJFGC': 'A person is carrying a box with a laptop on top down the stairs. They stop and stand as they take the laptop and open it. They sit on the stairs and start to work on it.', 'ON2VH': 'One person cooks at the stove, then takes a book and a camera and leaves the room.', 'FN457': 'A person is smiling into a mirror while grasping a picture.', 'WOD0G': 'A person runs into the entryway, carrying a towel and a book. The person throws the towel onto the table.', 'J4GX8': 'The person can sneeze while holding a glass, The person can take their medicine while drinking a glass of water.', 'YJ2CM': 'a person is holding a pillow while opening the stove.', '3SIOT': 'ONe person was laughing while holding a blanket. The other was throwing around a bag', 'WXUZK': 'Person A walks into the bedroom undressing and throwing the clothing onto a chair.  Person A them climbs onto the bed snuggling under the blanket and lying down.', 'GXIWH': 'A person is smiling at the bag and opening the coffee.', 'H40VV': 'A person is holding the door while another person is walking with the dishes.', 'V7KBN': 'Person pouring a drink after taking a glass from a shelf.  Person sneezing after leaving dining room.', '7W1ZI': 'Two persons are playing cards on the floor.  One person takes all the cards and puts them back in the box and closes it.  The person gets up and puts the deck of cards on the shelf next to a book.', '29T54': 'One person stands and starts undressing, opening a wardrobe cabinet to get clothes.', 'A9BDS': 'A person is standing over the sink. The person carries a bag into the dining room and sets it on the table before sitting down and pouring himself a drink.', 'PTA97': 'A person is seen fixing their hair at their closet. They start putting books inside the closet on a shelf.', 'MUAR4': 'A person is sitting on a chair, when they get up and walk away leaving a laptop on a desk.', 'VSWNF': 'A person is sitting on the stairs with a blanket.  The person then starts tidying a pile of homework.', '9FBAP': 'A person is laughing while opening the refrigerator and taking out a bag of carrots.', 'U6KQ7': 'A person is putting the excess food away from the table while they see the other person leaving and closing the door behind them.', 'F76GD': 'One person undresses, taking off a pair of shoes, then drinks from a glass and washes their hands.', 'WT9CR': 'One person is taking a picture with their laptop while another is playing by the door.', 'T03KF': 'The person is looking through their wardrobe and throwing clothes on the floor. They pick food up and begin eating it.', 'FCBEQ': 'A person is seen pouring food in a glass. They then start watching television and smiling', 'IA5TC': 'A person is putting a box on the shelf and then closing the cabinet.', 'YXPTI': 'One person is washing tennis shoes and a pillow while another person with a phone is leaving through the doorway.', 'FBIVN': 'A person is standing in the doorway, closes the door and grabs a pillow off a shelf and begins holding it.', '1RHDP': 'A person is walking with the vacuum. A pillow gets sucked up. The person rescues the pillow, and snuggles it.', 'J6L8A': 'The person is holding a broom while tidying the counter.  They then start pouring water into a pot on the stove.', 'D19IR': \"A person stands in a hallway looking out the window watching kids playing while holding a bag of groceries. The person is putting the bag on the floor to pick up the fallen broom so they don't trip over it.\", '4SN6Z': 'One person stands up, tidies up some dishes, then closes the stove and starts to cook.', 'M1P59': 'A person is eating in their pantry while playing on their phone. They grab a bag, and their shoes, and leave.', 'M1B7N': 'A person cooks something in a pot on the stove, then reaches over to open a cabinet door to grab some dishes from the shelf and place them next to the stove.  They then take a sip of coffee from a cup.', 'ZL7E9': 'One person takes medicine as another person laughs, standing at the stove with food.', '88LYX': 'A person is cooking on their stove. They stop momentarily, wash a glass, and go back to cooking.', 'S2RIQ': 'A person stands in the kitchen, cooking food on the stove.', 'IVJWH': 'A person is putting clothes on the sofa and begins sneezing at the smell of the food.', 'X1RBM': 'A person is playing with a mirror sitting on the toilet then begings to eat on top of the sink.', '48CYX': 'A person undresses in the bathroom. They begin washing themselves with a washcloth. They take a book from atop a shelf and walk out.', '3SDJE': 'A person is closing the stove and then puts a cook book back where it belongs.', 'SPKSE': 'A person is grasping a phone the puts a towel down.', 'UGMJZ': 'One person is throwing towels into the dryer. Another person is sitting on top of the dryer holding a book and reading.'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7su3Bijk9t4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "50cc262a-4c5e-4944-8335-2b49c547b9c6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subject</th>\n",
              "      <th>scene</th>\n",
              "      <th>quality</th>\n",
              "      <th>relevance</th>\n",
              "      <th>verified</th>\n",
              "      <th>script</th>\n",
              "      <th>objects</th>\n",
              "      <th>descriptions</th>\n",
              "      <th>actions</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46GP8</td>\n",
              "      <td>HR43</td>\n",
              "      <td>Kitchen</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person cooking on a stove while watching som...</td>\n",
              "      <td>food;stove;window</td>\n",
              "      <td>A person cooks food on a stove before looking ...</td>\n",
              "      <td>c092 11.90 21.20;c147 0.00 12.60</td>\n",
              "      <td>24.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N11GT</td>\n",
              "      <td>0KZ7</td>\n",
              "      <td>Stairs</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One person opens up a folded blanket, then sne...</td>\n",
              "      <td>blanket;broom;floor</td>\n",
              "      <td>Person at the bottom of the staircase shakes a...</td>\n",
              "      <td>c098 8.60 14.20;c075 0.00 11.70;c127 0.00 15.2...</td>\n",
              "      <td>18.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0IH69</td>\n",
              "      <td>6RE8</td>\n",
              "      <td>Bedroom</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person is seen leaving a cabinet. They then ...</td>\n",
              "      <td>book;box;cabinet;shelf</td>\n",
              "      <td>A person is standing in a bedroom. They walk o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KRF68</td>\n",
              "      <td>YA10</td>\n",
              "      <td>Laundry room</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person runs into their laundry room. They gr...</td>\n",
              "      <td>clothes;door;phone</td>\n",
              "      <td>A person runs in and shuts door. The person gr...</td>\n",
              "      <td>c018 22.60 27.80;c141 4.10 9.60;c148 10.30 25....</td>\n",
              "      <td>30.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MJO7C</td>\n",
              "      <td>6RE8</td>\n",
              "      <td>Kitchen</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person runs into their pantry holding a bott...</td>\n",
              "      <td>cup;phone</td>\n",
              "      <td>A person runs in place while holding a bottle ...</td>\n",
              "      <td>c015 0.00 32.00;c107 0.00 32.00</td>\n",
              "      <td>31.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id subject  ...                                            actions  length\n",
              "0  46GP8    HR43  ...                   c092 11.90 21.20;c147 0.00 12.60   24.83\n",
              "1  N11GT    0KZ7  ...  c098 8.60 14.20;c075 0.00 11.70;c127 0.00 15.2...   18.33\n",
              "2  0IH69    6RE8  ...                                                NaN   30.25\n",
              "3  KRF68    YA10  ...  c018 22.60 27.80;c141 4.10 9.60;c148 10.30 25....   30.33\n",
              "4  MJO7C    6RE8  ...                    c015 0.00 32.00;c107 0.00 32.00   31.38\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvgm7UeM_Gyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tp=df[\"actions\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QomtHi_w_q3K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4KIHBRo_K8-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAbTxT_G9xc4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "outputId": "f58bc37d-222d-46a5-8475-0165f4326943"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>MZOPX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>WT9CR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>BIK4X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2INEX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>F76GD</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0      0\n",
              "0           0  MZOPX\n",
              "1           1  WT9CR\n",
              "2           2  BIK4X\n",
              "3           3  2INEX\n",
              "4           4  F76GD"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmvnUUoE4Wgc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df2['0']\n",
        "# for x in df2['0']:\n",
        "#     print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFCva5kI3hsl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df2.rename( columns={'Unnamed: 1':'vid_id'}, inplace=True )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApCQa7udPCGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ar = []\n",
        "ar = [x for x in df2['0']]\n",
        "ar\n",
        "#ar=['0ZOPH', 'T7449', 'BA6DD', 'OVHFT', 'SH20Q', '5L04F', 'O2VP8', 'GPR89', '9EEGQ', 'PWR6D', '0RP6B', '0OP1K']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoeNCC1SHory",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"/content/drive/My Drive/Charades_v1_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NJluwraknsj",
        "colab_type": "code",
        "outputId": "129124f3-4577-4bcc-fa2a-8e3f1df1f1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>subject</th>\n",
              "      <th>scene</th>\n",
              "      <th>quality</th>\n",
              "      <th>relevance</th>\n",
              "      <th>verified</th>\n",
              "      <th>script</th>\n",
              "      <th>objects</th>\n",
              "      <th>descriptions</th>\n",
              "      <th>actions</th>\n",
              "      <th>length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46GP8</td>\n",
              "      <td>HR43</td>\n",
              "      <td>Kitchen</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person cooking on a stove while watching som...</td>\n",
              "      <td>food;stove;window</td>\n",
              "      <td>A person cooks food on a stove before looking ...</td>\n",
              "      <td>c092 11.90 21.20;c147 0.00 12.60</td>\n",
              "      <td>24.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N11GT</td>\n",
              "      <td>0KZ7</td>\n",
              "      <td>Stairs</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>One person opens up a folded blanket, then sne...</td>\n",
              "      <td>blanket;broom;floor</td>\n",
              "      <td>Person at the bottom of the staircase shakes a...</td>\n",
              "      <td>c098 8.60 14.20;c075 0.00 11.70;c127 0.00 15.2...</td>\n",
              "      <td>18.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0IH69</td>\n",
              "      <td>6RE8</td>\n",
              "      <td>Bedroom</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person is seen leaving a cabinet. They then ...</td>\n",
              "      <td>book;box;cabinet;shelf</td>\n",
              "      <td>A person is standing in a bedroom. They walk o...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>30.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>KRF68</td>\n",
              "      <td>YA10</td>\n",
              "      <td>Laundry room</td>\n",
              "      <td>6.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person runs into their laundry room. They gr...</td>\n",
              "      <td>clothes;door;phone</td>\n",
              "      <td>A person runs in and shuts door. The person gr...</td>\n",
              "      <td>c018 22.60 27.80;c141 4.10 9.60;c148 10.30 25....</td>\n",
              "      <td>30.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MJO7C</td>\n",
              "      <td>6RE8</td>\n",
              "      <td>Kitchen</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A person runs into their pantry holding a bott...</td>\n",
              "      <td>cup;phone</td>\n",
              "      <td>A person runs in place while holding a bottle ...</td>\n",
              "      <td>c015 0.00 32.00;c107 0.00 32.00</td>\n",
              "      <td>31.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id subject  ...                                            actions  length\n",
              "0  46GP8    HR43  ...                   c092 11.90 21.20;c147 0.00 12.60   24.83\n",
              "1  N11GT    0KZ7  ...  c098 8.60 14.20;c075 0.00 11.70;c127 0.00 15.2...   18.33\n",
              "2  0IH69    6RE8  ...                                                NaN   30.25\n",
              "3  KRF68    YA10  ...  c018 22.60 27.80;c141 4.10 9.60;c148 10.30 25....   30.33\n",
              "4  MJO7C    6RE8  ...                    c015 0.00 32.00;c107 0.00 32.00   31.38\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePTBCF97U2Os",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids=df[\"id\"].values.tolist()\n",
        "idx=[]\n",
        "label=[]\n",
        "data_feed_image_f=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DetSIHICZDz_",
        "colab_type": "code",
        "outputId": "3bbe790c-85f8-4ed7-93cd-cc10b4633170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(ar)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "301"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGM_Jj9EaMdK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24b770d6-ffd7-4ac4-b084-bee4f1690d38"
      },
      "source": [
        "len(idx)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssh8eRtrcEmU",
        "colab_type": "code",
        "outputId": "a7353090-8f11-4ca4-ee8e-4ef69116904a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_feed_image.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(301, 73, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sV_cs6NTVAA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i,v in enumerate(ar):\n",
        "  try:\n",
        "    idx.append(ids.index(v))\n",
        "    data_feed_image_f.append(data_feed_image[i])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liUOuHFDY-Ap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03nHVsi-cLtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_feed_image=np.asarray(data_feed_image_f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0f3tjlXahtP",
        "colab_type": "code",
        "outputId": "87a9671a-7ae1-4bb8-90d7-37a2a2e0618a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_feed_image.shape"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(301, 73, 2048)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqhdcgDdNnKs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scripts=df['script'].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNwHMu_5cver",
        "colab_type": "code",
        "outputId": "c2da73d9-7c77-43b1-b00f-dfce4c199d65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "scripts[:2]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A person cooking on a stove while watching something out a window.',\n",
              " 'One person opens up a folded blanket, then sneezes and leaves the stairs with a broom.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z76gQx6Nt-nf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embed_useT(module):\n",
        "    with tf.Graph().as_default():\n",
        "        sentences = tf.placeholder(tf.string)\n",
        "        embed = hub.Module(module)\n",
        "        embeddings = embed(sentences)\n",
        "        session = tf.train.MonitoredSession()\n",
        "    return lambda x: session.run(embeddings, {sentences: x})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uat9ZQOJvm1d",
        "colab_type": "code",
        "outputId": "d0e3cb27-4723-4cb8-daed-a07ac55f49c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "embed_fn = embed_useT('/content/drive/My Drive/USE/')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3lAV1XrB0Hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "script=[]\n",
        "for _,i in enumerate(idx):\n",
        "  \n",
        "  script.append(scripts[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pK3Nf6kuA7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_encoding=embed_fn(script)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpKFyA-wFfrK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_feed_sentence=sentence_encoding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wPHknhqe3CE",
        "colab_type": "code",
        "outputId": "ef7f45c0-adfc-4afa-faf3-601d31b6b198",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_feed_sentence.shape"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(301, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RW4yJWtIGDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab=set()\n",
        "for i in df['script']:\n",
        "  v=i.split()\n",
        "  vocab.update(v)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZoNFkcHI1aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_len=len(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Pd9xgNwNhbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tok = Tokenizer(num_words=30000,lower=True)\n",
        "tok.fit_on_texts(vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoqwC_FpNnnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_script=tok.texts_to_sequences(scripts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLJrwhVZNnHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_seq_len=0\n",
        "a=[]\n",
        "for i in seq_script:\n",
        "  a.append(len(i))\n",
        "  if len(i)>max_seq_len:\n",
        "    max_seq_len=len(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoKgukEofC2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2idx = tok.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKiU2f6LRc-D",
        "colab_type": "code",
        "outputId": "da1b42e4-dba1-4843-8429-890cd8b51a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_seq_len"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH8c_pZfRxlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mn=st.mean(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oq8LOdpShyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std=st.stdev(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5kk4pkeUFru",
        "colab_type": "code",
        "outputId": "8b7d1b21-a0bb-4e3f-caef-ca544d8590ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "thresh=int((mn+(3*std)))\n",
        "thresh"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm-aY8TRcOc3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresh=42"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkmBYGsVbz3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for ind,val in enumerate(seq_script):\n",
        "  seq_script[ind]=seq_script[ind][:thresh]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXh_FkbnUR0G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_feed_script= pad_sequences(seq_script, maxlen=thresh+1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCjN07iOVy9N",
        "colab_type": "code",
        "outputId": "81915652-689e-40ee-9eed-eadc63c138f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_feed_script.shape"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7985, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oBnyqGGfDC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_feed_words=[]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmjhsivPe8Ao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in idx:\n",
        "  data_feed_words.append(data_feed_script[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r3iCAlhftnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_feed_words=np.asarray(data_feed_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ5NsgeQf19M",
        "colab_type": "code",
        "outputId": "529c2bc8-1692-4713-8a1f-03f81706cd59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(data_feed_words.shape)\n",
        "print(data_feed_sentence.shape)\n",
        "print(data_feed_image.shape)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(301, 43)\n",
            "(301, 512)\n",
            "(301, 73, 2048)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cSTRsalIeC_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "emb={}\n",
        "with open(os.path.join('/content/drive/My Drive/glove.6B.50d.txt')) as f :\n",
        "  for l in f:\n",
        "    v=l.split()\n",
        "    w=v[0]\n",
        "    emb[w]=v[1:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ozVg1fqeG0f",
        "colab_type": "code",
        "outputId": "c69c4a62-086e-41b4-b012-c8f480436405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "t={}\n",
        "emb_dim=50\n",
        "num_words =vocab_len+1 \n",
        "embedding_matrix = np.zeros((num_words,emb_dim),dtype=np.float32)\n",
        "for word,i in word2idx.items():\n",
        "  embedding_vector = emb.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = np.asarray(embedding_vector)\n",
        "  else:\n",
        "    t[word]=i\n",
        "    # embedding_matrix[i] = np.asarray(emb.get(\"unk\"))\n",
        "print(t)\n",
        "print(len(t))"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'selfie': 421, 'selfies': 423, \"that's\": 479, \"they're\": 481, \"it's\": 674, 'begans': 800, 'frig': 830, 'coffe': 864, 'sittiing': 868, \"couldn't\": 886, 'refridgerator': 905, \"won't\": 1032, \"can't\": 1067, \"aren't\": 1094, 'bathrom': 1140, \"doesn't\": 1147, \"what's\": 1151, 'doornobo': 1191, \"wouldn't\": 1268, \"weren't\": 1315, 'smiliing': 1318, 'processds': 1320, 'thens': 1358, \"person's\": 1378, \"anyone's\": 1379, \"home's\": 1384, \"get's\": 1394, \"they've\": 1434, 'vegins': 1454, \"pantry's\": 1470, \"window's\": 1482, 'theu': 1490, 'enterway': 1543, \"don't\": 1549, \"night's\": 1573, \"bedroom's\": 1577, 'begings': 1587, \"didn't\": 1601, \"camera's\": 1605, 'neaten': 1634, \"who's\": 1635, \"clock's\": 1644, 'vacum': 1668, 'quiddith': 1674, \"phone's\": 1779, 'visable': 1939, \"house's\": 1995, 'laudry': 2004, \"fly's\": 2190, 'bathrooom': 2201, \"door's\": 2244, 'decines': 2267, 'teddybear': 2286}\n",
            "53\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LetIutfOfuKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=156"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBbMOGktWxzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tp=df[\"actions\"].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X74QQxqGW4i4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=[]\n",
        "for i in idx:\n",
        "  label.append(int(tp[i].split()[0][1:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXxEALfkYfrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=np.asarray(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaVse3XcY37J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db89bd66-5208-4887-eab7-5bb24412161d"
      },
      "source": [
        "label.shape"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(301,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv-bjSYPXrpQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=np.reshape(label,(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i1UYeiYYQGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "303cab57-01ef-4178-bc6d-e03304b429ef"
      },
      "source": [
        "label.shape"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(301, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAoKRWzalo99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network(text,act,sen):\n",
        "  with tf.variable_scope('Action'):\n",
        "    act_out=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,return_sequences=False))(act)\n",
        "  print(act_out.shape)\n",
        "\n",
        "  with tf.variable_scope('Text'):\n",
        "    text_out=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(50,return_sequences=False))(text)  \n",
        "  print(text_out.shape)  \n",
        "\n",
        "  with tf.variable_scope('Sentence'):\n",
        "    st=tf.keras.layers.Dense(250,activation='relu')(sen)\n",
        "    st=tf.keras.layers.Dense(100,activation='relu')(st)\n",
        "\n",
        "  fused_stacked_layer=tf.stack([act_out,text_out,st],axis=1)\n",
        "  print(fused_stacked_layer.shape)\n",
        "\n",
        "  fused_concat_layer=tf.keras.layers.Concatenate()([act_out,text_out,st])\n",
        "  print(fused_concat_layer.shape)\n",
        "\n",
        "  fused_atten_dense=tf.keras.layers.Dense(128,activation='relu')(fused_concat_layer)\n",
        "  fused_atten_out=tf.keras.layers.Dense(3,activation='softmax')(fused_atten_dense)\n",
        "  print(fused_atten_out.shape)\n",
        "\n",
        "  fused_out_fin = tf.multiply(tf.expand_dims(fused_atten_out,2),fused_stacked_layer)\n",
        "  print(fused_out_fin.shape)\n",
        "\n",
        "  fused_out_fin = tf.reshape(fused_out_fin,[tf.shape(fused_out_fin)[0],fused_out_fin.shape[1]*fused_out_fin.shape[2]])\n",
        "  print(fused_out_fin.shape)\n",
        "\n",
        "  fused_fc=tf.keras.layers.Dense(170,activation='relu')(fused_out_fin)\n",
        "  fused_fc_logits=tf.keras.layers.Dense(classes)(fused_fc)\n",
        "  fused_fc_sft=tf.nn.softmax(fused_fc_logits)\n",
        "  return fused_fc_logits,fused_fc_sft,fused_atten_out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZLUBILmVv9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data_feed_image=data_feed_image[-50:]\n",
        "test_data_feed_words=data_feed_words[-50:]\n",
        "test_data_feed_sentence=data_feed_sentence[-50:]\n",
        "test_label=label[-50:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyhqQtbpfDD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=label[:-50]\n",
        "data_feed_image=data_feed_image[:-50]\n",
        "data_feed_words=data_feed_words[:-50]\n",
        "data_feed_sentence=data_feed_sentence[:-50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEOEnIwAqi3T",
        "colab_type": "code",
        "outputId": "3d6707b8-c943-4ad2-e11f-0a4630d2bc7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_frames =73\n",
        "embedding_size = 2048\n",
        "ACTION=tf.placeholder(tf.float32,[None,max_frames, embedding_size])\n",
        "TEXT=tf.placeholder(tf.int32,[None,thresh+1])\n",
        "SENTENCE=tf.placeholder(tf.float32,[None,512])\n",
        "Y=tf.placeholder(tf.int32,[None,1])\n",
        "\n",
        "word_embeddings=tf.Variable(embedding_matrix,name=\"emb\",trainable=False,dtype=tf.float32)\n",
        "txt= tf.nn.embedding_lookup(word_embeddings,TEXT)\n",
        "\n",
        "logit,prob,atten=network(txt,ACTION,SENTENCE)\n",
        "one_hot=tf.one_hot(indices=Y,depth=classes,axis=-1)\n",
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=one_hot,logits=logit))\n",
        "\n",
        "with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
        "  optimizer=tf.train.AdamOptimizer(0.001).minimize(loss)\n",
        "loss_graph,x_axis,val_loss_graph=[],[],[]\n",
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  for ep in range(1000):\n",
        "    l,f,_=sess.run([loss,atten,optimizer],feed_dict={ACTION:data_feed_image,TEXT:data_feed_words,Y:label,SENTENCE:data_feed_sentence})\n",
        "    print(ep,\"train loss :\",l)\n",
        "    loss_graph.append(l)\n",
        "    x_axis.append(ep)\n",
        "    l=sess.run(loss,feed_dict={ACTION:test_data_feed_image,TEXT:test_data_feed_words,Y:test_label,SENTENCE:test_data_feed_sentence})\n",
        "    val_loss_graph.append(l)\n",
        "    print(\"valid loss :\",l)\n",
        "    print(\"atten values  IMAGE  WORDS  SENTENCE\",np.mean(f, axis=0))\n",
        "\n",
        "\n",
        "  "
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 100)\n",
            "(?, 100)\n",
            "(?, 3, 100)\n",
            "(?, 300)\n",
            "(?, 3)\n",
            "(?, 3, 100)\n",
            "(?, 300)\n",
            "0 train loss : 5.00025\n",
            "valid loss : 5.033909\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.3220275  0.29423636 0.38373607]\n",
            "1 train loss : 4.981746\n",
            "valid loss : 5.020772\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.308387   0.2897455  0.40186748]\n",
            "2 train loss : 4.961009\n",
            "valid loss : 5.011835\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.3164649  0.25963217 0.42390293]\n",
            "3 train loss : 4.943684\n",
            "valid loss : 5.000597\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.3330278  0.2525004  0.41447186]\n",
            "4 train loss : 4.924538\n",
            "valid loss : 4.9867296\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.3765884  0.24037544 0.38303617]\n",
            "5 train loss : 4.906671\n",
            "valid loss : 4.9769745\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.42936924 0.22700146 0.3436291 ]\n",
            "6 train loss : 4.8790665\n",
            "valid loss : 4.9552\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.5000396  0.19131394 0.30864635]\n",
            "7 train loss : 4.8466277\n",
            "valid loss : 4.935337\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.5813374  0.15800509 0.26065728]\n",
            "8 train loss : 4.816059\n",
            "valid loss : 4.908139\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.66252935 0.12651215 0.21095847]\n",
            "9 train loss : 4.7784147\n",
            "valid loss : 4.89144\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.7459531  0.09213701 0.16190952]\n",
            "10 train loss : 4.738166\n",
            "valid loss : 4.868505\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.827365   0.05975447 0.11288074]\n",
            "11 train loss : 4.7015395\n",
            "valid loss : 4.8505635\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.8979543  0.03392606 0.06811977]\n",
            "12 train loss : 4.6607924\n",
            "valid loss : 4.832349\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.9428725  0.01812765 0.03899951]\n",
            "13 train loss : 4.623674\n",
            "valid loss : 4.8164954\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.9710975  0.00851423 0.02038858]\n",
            "14 train loss : 4.589302\n",
            "valid loss : 4.8082595\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.9867149  0.0035581  0.00972691]\n",
            "15 train loss : 4.5513973\n",
            "valid loss : 4.7944927\n",
            "atten values  IMAGE  WORDS  SENTENCE [0.9941125  0.00140193 0.00448544]\n",
            "16 train loss : 4.5179377\n",
            "valid loss : 4.7862864\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9764723e-01 5.1643507e-04 1.8362545e-03]\n",
            "17 train loss : 4.4799414\n",
            "valid loss : 4.774786\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9905229e-01 1.9048396e-04 7.5693749e-04]\n",
            "18 train loss : 4.446174\n",
            "valid loss : 4.769012\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.996019e-01 7.183940e-05 3.262212e-04]\n",
            "19 train loss : 4.4084888\n",
            "valid loss : 4.764409\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9982494e-01 2.8103928e-05 1.4684381e-04]\n",
            "20 train loss : 4.3731856\n",
            "valid loss : 4.768879\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9991852e-01 1.1885506e-05 6.9585127e-05]\n",
            "21 train loss : 4.347748\n",
            "valid loss : 4.784374\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9995947e-01 5.1694124e-06 3.5476980e-05]\n",
            "22 train loss : 4.31632\n",
            "valid loss : 4.819131\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9997997e-01 2.2154336e-06 1.7533441e-05]\n",
            "23 train loss : 4.283458\n",
            "valid loss : 4.869378\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999213e-01 8.6283148e-07 7.6682372e-06]\n",
            "24 train loss : 4.258461\n",
            "valid loss : 4.9408846\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999815e-01 3.1181116e-07 2.9905202e-06]\n",
            "25 train loss : 4.2455006\n",
            "valid loss : 4.974705\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999946e-01 1.3143897e-07 1.2671968e-06]\n",
            "26 train loss : 4.2242203\n",
            "valid loss : 4.9648876\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999982e-01 7.8665714e-08 7.7762292e-07]\n",
            "27 train loss : 4.202291\n",
            "valid loss : 4.939898\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.999999e-01 5.691476e-08 5.773426e-07]\n",
            "28 train loss : 4.1854515\n",
            "valid loss : 4.939337\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999994e-01 4.5306699e-08 4.7441085e-07]\n",
            "29 train loss : 4.1872907\n",
            "valid loss : 4.9654775\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999994e-01 3.6870976e-08 4.0098627e-07]\n",
            "30 train loss : 4.182987\n",
            "valid loss : 4.9726825\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999994e-01 2.8822045e-08 3.2549741e-07]\n",
            "31 train loss : 4.158797\n",
            "valid loss : 4.9668713\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999994e-01 2.1820579e-08 2.5252911e-07]\n",
            "32 train loss : 4.1406536\n",
            "valid loss : 4.9950933\n",
            "atten values  IMAGE  WORDS  SENTENCE [9.9999994e-01 1.5249359e-08 1.8965103e-07]\n",
            "33 train loss : 4.1199517\n",
            "valid loss : 5.022304\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 1.1232777e-08 1.4893793e-07]\n",
            "34 train loss : 4.0909247\n",
            "valid loss : 5.0527177\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 7.9008649e-09 1.1012086e-07]\n",
            "35 train loss : 4.0787487\n",
            "valid loss : 5.0674562\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 5.5063274e-09 8.1823600e-08]\n",
            "36 train loss : 4.0707564\n",
            "valid loss : 5.0724506\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 4.0397725e-09 6.3337971e-08]\n",
            "37 train loss : 4.0540476\n",
            "valid loss : 5.0827904\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 3.1684482e-09 5.2069115e-08]\n",
            "38 train loss : 4.0339475\n",
            "valid loss : 5.1019053\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 2.4868827e-09 4.2190674e-08]\n",
            "39 train loss : 4.018415\n",
            "valid loss : 5.1209106\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 1.9485398e-09 3.3671146e-08]\n",
            "40 train loss : 3.9963934\n",
            "valid loss : 5.149226\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 1.6446242e-09 2.9119809e-08]\n",
            "41 train loss : 3.971448\n",
            "valid loss : 5.160062\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 1.3887009e-09 2.4807052e-08]\n",
            "42 train loss : 3.9514015\n",
            "valid loss : 5.155884\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 1.2087648e-09 2.1405402e-08]\n",
            "43 train loss : 3.938274\n",
            "valid loss : 5.158312\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 1.0386506e-09 1.8359421e-08]\n",
            "44 train loss : 3.9216306\n",
            "valid loss : 5.1874304\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 8.9865809e-10 1.6096687e-08]\n",
            "45 train loss : 3.8910213\n",
            "valid loss : 5.1943636\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.000000e+00 8.025506e-10 1.491417e-08]\n",
            "46 train loss : 3.8760178\n",
            "valid loss : 5.225547\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 7.0928502e-10 1.3570134e-08]\n",
            "47 train loss : 3.8563783\n",
            "valid loss : 5.263246\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 6.0175692e-10 1.1628183e-08]\n",
            "48 train loss : 3.8382902\n",
            "valid loss : 5.261631\n",
            "atten values  IMAGE  WORDS  SENTENCE [1.0000000e+00 4.9503046e-10 9.6572021e-09]\n",
            "49 train loss : 3.8173144\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-363-bcbd23d7a4a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mx_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0ml\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mACTION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_data_feed_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTEXT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_data_feed_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSENTENCE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtest_data_feed_sentence\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mval_loss_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"valid loss :\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1147\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m           if (not is_tensor_handle_feed and\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ2TtTXOq8lQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(x_axis,loss_graph, label = \"TRAIN LOSS WITH LSTMS\")\n",
        "# plt.plot(x_axis,val_loss_graph, label = \"TRAIN LOSS WITH CNN\")\n",
        "plt.ylim(0,5) \n",
        "plt.xlim(0,15) \n",
        "plt.xlabel('epoch')  \n",
        "plt.ylabel('loss') \n",
        "plt.title('CHECK FITTING')\n",
        "plt.legend() \n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S400sDoCjTAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGKGMN_LjAuE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}